# Project Scope: Database Observability Collection Layer

This document clearly defines what this project **does** and **does not** do.

---

## âœ… What This Project DOES

### 1. Data Collection
- âœ… Connects to PostgreSQL databases (agentless, read-only)
- âœ… Collects metrics via OpenTelemetry Collector
- âœ… Collects logs via custom Python collector
- âœ… Collects query analytics via pg_stat_statements
- âœ… Generates test database load for development

### 2. Data Publishing
- âœ… Publishes **raw, unprocessed** data to Kafka
- âœ… Three topics: `otel-metrics`, `raw-logs`, `raw-queries`
- âœ… OTLP format for metrics (binary protobuf)
- âœ… JSON format for logs and queries

### 3. Infrastructure
- âœ… PostgreSQL database with monitoring user
- âœ… Single Kafka instance (`kafka-ingestion`)
- âœ… OpenTelemetry Collector container
- âœ… Python Collector container
- âœ… Load Simulator container
- âœ… Kafka UI for topic monitoring

### 4. Development Tools
- âœ… Docker Compose setup
- âœ… Makefile with useful commands
- âœ… Health checks
- âœ… Debugging tools
- âœ… Local development environment

---

## âŒ What This Project DOES NOT Do

### 1. Data Processing
- âŒ No data normalization
- âŒ No data enrichment
- âŒ No data aggregation
- âŒ No data transformation
- âŒ No schema evolution

### 2. Data Storage
- âŒ No VAST Database integration
- âŒ No long-term storage
- âŒ No data warehouse
- âŒ No time-series database
- âŒ Data only retained in Kafka (7-90 days)

### 3. Data Consumption
- âŒ No output Kafka topics
- âŒ No processed data streams
- âŒ No alert generation
- âŒ No downstream processors
- âŒ No event-driven actions

### 4. Visualization & Analytics
- âŒ No dashboards
- âŒ No Apache Superset
- âŒ No Trino/Presto query engine
- âŒ No BI tools integration
- âŒ No reports

### 5. Advanced Features
- âŒ No MongoDB support (code exists but not deployed)
- âŒ No Redis support (code exists but not deployed)
- âŒ No Bytewax streaming processor
- âŒ No VAST Functions integration
- âŒ No AI/ML analytics
- âŒ No anomaly detection
- âŒ No correlation engine

### 6. Production Features
- âŒ No authentication/authorization
- âŒ No TLS/SSL encryption
- âŒ No multi-tenancy
- âŒ No high availability
- âŒ No disaster recovery
- âŒ No observability of the observability system

---

## ğŸ”„ What Belongs in the Processor Project

The separate **`vastdb-processor`** project should implement:

### Data Processing Pipeline
```
[Kafka Ingestion Topics]
       â†“
   [Bytewax Streaming / VAST Functions]
       â†“
   [vastdb-observability Python Library]
       â”œâ”€â”€ Normalizer (common schema)
       â”œâ”€â”€ Enricher (add metadata)
       â”œâ”€â”€ Aggregator (time-series rollups)
       â””â”€â”€ Validator (data quality)
       â†“
[Kafka Output Topics]
       â”œâ”€â”€ processed-metrics
       â”œâ”€â”€ processed-logs
       â”œâ”€â”€ processed-queries
       â””â”€â”€ alerts
       â†“
   [VAST Database]
       â”œâ”€â”€ db_metrics table
       â”œâ”€â”€ db_logs table
       â””â”€â”€ db_queries table
       â†“
   [Analytics Layer]
       â”œâ”€â”€ Trino (SQL queries)
       â”œâ”€â”€ Superset (dashboards)
       â””â”€â”€ AI Agents (insights)
```

### Components Needed in Processor
1. **vastdb-observability Python library**
   - `collectors/` (from ingestion topics, not databases)
   - `processors/` (normalize, enrich, aggregate)
   - `exporters/` (to output Kafka, VAST DB)

2. **Bytewax dataflow** or **VAST Functions**
   - Streaming data processor
   - Stateful aggregations
   - Windowing operations

3. **Output Kafka instance** (`kafka-output`)
   - Separate from ingestion Kafka
   - Clean separation of concerns
   - Processed data only

4. **VAST Database**
   - Time-series optimized storage
   - SQL interface via Trino
   - Long-term retention (years)

5. **Analytics Layer**
   - Trino query engine
   - Apache Superset dashboards
   - Pre-built observability dashboards

6. **Alerting System**
   - Rule engine
   - Alert aggregation
   - Notification channels

---

## ğŸ“Š Data Flow Architecture

### Current Project (Collection)
```
[Databases] â†’ [Collectors] â†’ [kafka-ingestion] â†’ (end here)
                                  â†“
                           [Kafka UI for monitoring]
```

### Complete System (with Processor)
```
[Databases] â†’ [Collectors] â†’ [kafka-ingestion] 
                                  â†“
                           [Processor Service]
                                  â†“
                           [kafka-output]
                                  â†“
                           [VAST Database]
                                  â†“
                           [Analytics/Dashboards]
```

---

## ğŸ¯ Project Boundaries Summary

| Capability | This Project | Processor Project |
|------------|--------------|-------------------|
| Database connection | âœ… Yes | âŒ No |
| Metrics collection | âœ… Yes | âŒ No |
| Raw data publishing | âœ… Yes | âŒ No |
| Data processing | âŒ No | âœ… Yes |
| Data enrichment | âŒ No | âœ… Yes |
| Data storage | âŒ No | âœ… Yes |
| Visualization | âŒ No | âœ… Yes |
| Alerting | âŒ No | âœ… Yes |

---

## ğŸš€ Integration Points

### How This Project Connects to Processor

**Topic Interface:**
- This project **produces** to: `otel-metrics`, `raw-logs`, `raw-queries`
- Processor project **consumes** from: same topics
- Clean decoupling via Kafka

**No Direct Integration:**
- No shared databases
- No shared code (initially)
- No RPC calls
- Independent deployment
- Independent scaling

**Shared Library (Future):**
- `vastdb-observability` Python library
- Common data models
- Shared utilities
- But each project uses different modules

---

## ğŸ“ Repository Structure Recommendation

### Option 1: Monorepo
```
db-observability/
â”œâ”€â”€ collection/          # This project
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ otel-collector/
â”‚   â”œâ”€â”€ python-collector/
â”‚   â””â”€â”€ load-simulator/
â”œâ”€â”€ processor/           # Processor project
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ bytewax-processor/
â”‚   â””â”€â”€ vast-functions/
â”œâ”€â”€ shared/
â”‚   â””â”€â”€ vastdb-observability/  # Shared Python library
â””â”€â”€ docs/
```

### Option 2: Separate Repos (Current)
```
db-observability-collection/    # This repo
â””â”€â”€ (everything in this project)

vastdb-processor/              # Separate repo
â””â”€â”€ (processor implementation)

vastdb-observability/          # Shared library repo
â””â”€â”€ (Python library package)
```

---

## ğŸ”§ Development Workflow

### Working on Collection Layer Only
```bash
cd db-observability-collection/
make up
make kafka-consume-queries  # See raw data
```

### Working on Processor
```bash
# Terminal 1: Start collection layer
cd db-observability-collection/
make up

# Terminal 2: Start processor
cd vastdb-processor/
make up

# Data flows: Collection â†’ kafka-ingestion â†’ Processor â†’ kafka-output â†’ VAST DB
```

### Testing Integration
```bash
# Check data flow
make kafka-topics  # Should see all topics

# Consume from ingestion
make kafka-consume-queries

# Consume from output (in processor project)
make kafka-consume-processed
```

---

## ğŸ“ Understanding the Design

### Why Separate Projects?

1. **Separation of Concerns**
   - Collection: Get data from sources
   - Processing: Transform data
   - Clear responsibilities

2. **Independent Scaling**
   - Scale collectors based on # of databases
   - Scale processors based on data volume
   - Different resource requirements

3. **Development Velocity**
   - Teams can work independently
   - Faster iteration cycles
   - Smaller, focused codebases

4. **Deployment Flexibility**
   - Deploy collection close to databases
   - Deploy processor in central location
   - Different update cadences

5. **Technology Flexibility**
   - Collection uses OTel + Python
   - Processor can use Bytewax/Spark/Flink
   - Change one without affecting the other

---

## ğŸ“ Next Steps

1. **Complete this project:**
   - âœ… Fix remaining bugs
   - âœ… Add documentation
   - âœ… Test with multiple databases
   - âœ… Production hardening

2. **Start processor project:**
   - Create new repository/folder
   - Implement vastdb-observability library
   - Build Bytewax processor
   - Integrate VAST Database
   - Create dashboards

3. **Integration testing:**
   - Run both projects together
   - Verify end-to-end data flow
   - Performance testing
   - Failure scenarios

---

## âš ï¸ Common Misconceptions

### âŒ Wrong: "This is the complete observability platform"
**âœ… Correct:** This is only the collection layer. Processor is needed for storage and analytics.

### âŒ Wrong: "Data in Kafka is processed and enriched"
**âœ… Correct:** Data in Kafka is raw and unprocessed. Processing happens in separate project.

### âŒ Wrong: "I can query historical data from this project"
**âœ… Correct:** Only Kafka retention (7-90 days). VAST Database in processor project for historical queries.

### âŒ Wrong: "Dashboards and alerts are included"
**âœ… Correct:** No visualization or alerting. That's in the processor project with Superset.

### âŒ Wrong: "kafka-output should be in this project"
**âœ… Correct:** Only kafka-ingestion is needed here. kafka-output belongs in processor project.

---

## ğŸ¯ Success Criteria

### For This Project
- âœ… Collectors run reliably
- âœ… Data flows to Kafka topics
- âœ… Topics contain expected data formats
- âœ… Health checks pass
- âœ… Documentation is complete

### For Complete System (Collection + Processor)
- âœ… Data stored in VAST Database
- âœ… Dashboards show insights
- âœ… Alerts fire on anomalies
- âœ… Query performance is good
- âœ… System scales to 100+ databases

---

This document serves as the contract between the collection and processor projects. Any changes to topic schemas or data formats should be coordinated between teams.